{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import memory_profiler\n",
    "from metro.ita import *\n",
    "from metro import multiplex as mx\n",
    "import cProfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "multi = mx.read_multi()\n",
    "multi.read_od(layer = 'taz', key = 'taz', od_file = '1_data/taz_od/0_1.txt', sep = \" \")\n",
    "g, od = multi.to_igraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_nodes = 50\n",
    "sub_od = {key : od[key] for key in od.keys()[:n_nodes]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary_constructor(es, base_cost):\n",
    "    def get_path_summary(path):\n",
    "        edges = eval(path)\n",
    "        congested_time_m = sum([es[e]['congested_time_m'] for e in edges])\n",
    "        uniform_time_m = sum([es[e]['uniform_time_m'] for e in edges])\n",
    "        free_flow_time_m = sum([es[e]['free_flow_time_m'] for e in edges])\n",
    "        dist_km = sum([es[e]['dist_km'] for e in edges])\n",
    "        base = sum([es[e][base_cost] for e in edges])\n",
    "        weighted_capacity = (1.0 * sum([es[e]['dist_km']*es[e]['capacity'] for e in edges]))\n",
    "        weighted_flow = (1.0 * sum([es[e]['dist_km']*es[e]['flow'] for e in edges]))\n",
    "        gamma = [weighted_flow / weighted_capacity if weighted_capacity > 0 else np.nan][0]\n",
    "        gradient = (1.0 * sum([es[e]['gradient'] for e in edges]))\n",
    "        return (congested_time_m, uniform_time_m, free_flow_time_m, dist_km, base, gamma, gradient)\n",
    "    return get_path_summary\n",
    "\n",
    "def make_details_df(df, es, base_cost):\n",
    "    get_path_summary = summary_constructor(es, base_cost)\n",
    "    df['congested_time_m'], df['uniform_time_m'], df['free_flow_time_m'], df['dist_km'], df['base_cost'], df['gamma'], df['gradient'] = zip(*df['path'].map(get_path_summary))\n",
    "    del df['path']\n",
    "    return df[['o', 'd', 'p', 'flow', 'dist_km', 'uniform_time_m', 'free_flow_time_m', 'congested_time_m', 'base_cost', 'gamma', 'gradient']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ITA(g, od, base_cost = 'free_flow_time_m', P = [0.4, 0.3, 0.2, 0.1], a = 0.15, b = 4., scale = .25, details = False):\n",
    "    \n",
    "    import time \n",
    "    \n",
    "\n",
    "    columns = ['o', 'd', 'p', 'flow', 'path']\n",
    "    flow_dict = defaultdict(int)\n",
    "\n",
    "    es = g.es\n",
    "    \n",
    "    es['flow'] = 0\n",
    "    es['congested_time_m'] = list(es[base_cost])\n",
    "    \n",
    "    j = 0\n",
    "    for p in P: \n",
    "        start = time.clock()\n",
    "        paths_list = pd.DataFrame(columns = columns)\n",
    "        for o in od:\n",
    "            ds = od[o]\n",
    "            if len(ds) > 0:\n",
    "                targets = ds.keys()\n",
    "                paths = g.get_shortest_paths(o, \n",
    "                                             to=targets, \n",
    "                                             weights='congested_time_m', \n",
    "                                             mode='OUT', \n",
    "                                             output=\"epath\")\n",
    "\n",
    "                # Update flow dict\n",
    "                for i in range(len(targets)):\n",
    "                        flow = od[o][targets[i]]\n",
    "                        for e in paths[i]:\n",
    "                            flow_dict[e] += p * scale * flow\n",
    "\n",
    "\n",
    "                # Update paths list\n",
    "                if details:\n",
    "                    update_piece = [{'o' : o, \n",
    "                    'd' : targets[i], \n",
    "                    'p' : p,\n",
    "                    'flow' : scale * od[o][targets[i]], \n",
    "                    'path' : str(paths[i])} for i in range(len(targets))]\n",
    "                    update_piece = pd.DataFrame(update_piece)\n",
    "                    paths_list = paths_list.append(update_piece)\n",
    "                \n",
    "\n",
    "        # Assign the flows to the graph\n",
    "        for key in flow_dict:\n",
    "            es[key]['flow'] = flow_dict[key]\n",
    "            es[key]['congested_time_m'] = BPR(base = es[key][base_cost], \n",
    "                                    flow = es[key]['flow'], \n",
    "                                    capacity = float(es[key]['capacity']),\n",
    "                                    a = a,\n",
    "                                    b = b)\n",
    "        if details:\n",
    "            paths_list.to_csv('3_throughput/paths_list_' + str(j) + '.csv')\n",
    "            j += 1\n",
    "            del paths_list\n",
    "        print 'assignment for p = ' + str(p) + ' completed in ' + str(round((time.clock() - start) / 60.0, 1)) + 'm'\n",
    "        \n",
    "\n",
    "    compute_gradient('free_flow_time_m', 'flow', 'capacity', a, b, es)\n",
    "    \n",
    "    # Compute details\n",
    "    if details:\n",
    "        df = pd.DataFrame(columns = columns)\n",
    "        for k in range(len(P)):\n",
    "            df = df.append(pd.read_csv('3_throughput/paths_list_' + str(k) + '.csv'))\n",
    "            os.remove('3_throughput/paths_list_' + str(k) + '.csv')\n",
    "        df = make_details_df(df, es, base_cost)\n",
    "        df = agg_df(df)\n",
    "        con_map = { v.index : v['con_name'] for v in g.vs}\n",
    "        df['o_con'] = df.o.map(con_map.get)\n",
    "        df['d_con'] = df.d.map(con_map.get)\n",
    "        nx_map = { v.index : v['name'] for v in g.vs}\n",
    "        df['o_nx'] = df.o.map(nx_map.get)\n",
    "        df['d_nx'] = df.d.map(nx_map.get)\n",
    "        del df['o']\n",
    "        del df['d']\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assignment for p = 0.4 completed in 16.7m\n",
      "assignment for p = 0.3 completed in 32.9m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-458486eb7607>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mITA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetails\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-ab587b08a4c2>\u001b[0m in \u001b[0;36mITA\u001b[1;34m(g, od, base_cost, P, a, b, scale, details)\u001b[0m\n\u001b[0;32m     41\u001b[0m                     'path' : str(paths[i])} for i in range(len(targets))]\n\u001b[0;32m     42\u001b[0m                     \u001b[0mupdate_piece\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_piece\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                     \u001b[0mpaths_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpaths_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_piece\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = ITA(g, od, details = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
